\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Automation of Inter-Rater Reliability (IRR)},
            pdfauthor={Ailbhe N. Finnerty},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Automation of Inter-Rater Reliability (IRR)}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Ailbhe N. Finnerty}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{04 November2019}


\begin{document}
\maketitle

\subsection{\texorpdfstring{Markdown for
``IRR\_Automation.R''}{Markdown for IRR\_Automation.R}}\label{markdown-for-irr_automation.r}

This is an R Markdown document to provide instructions on how to run the
R script
\textbf{\url{https://github.com/HumanBehaviourChangeProject/Automation-InterRater-Reliability/blob/master/Automation_IRR_Krippendorf.R}}
to automate the calculation of Inter-rater reliability (IRR) using R
package \textbf{`irr'}. This work is part of the Human Behaviour Change
Project \url{https://www.humanbehaviourchange.org/}. More information
about the methods used to development this script is currently being
written up and will be available online by January 2020.

The input for this script is one or more csv files with at least three
columns, if more than one file they must match in both name and number
of columns. The basic necessary data structure is \textbf{1)} a column
for the \textbf{entity/attribute} that you want to calculate IRR for,
\textbf{2)} a column of binary data from Coder 1 and \textbf{3)} a
column of binary data for Coder 2.

The data used in this example are two csv files (``Behaviour1.csv'' and
``Behaviour2.csv'') from a parsed JSON file of annotations created by
EPPI reviewer \textbf{\url{https://eppi.ioe.ac.uk/cms/}}. The data is
parsed from the JSON files using a python script which can be found at
\textbf{\url{https://github.com/HumanBehaviourChangeProject/Automation-InterRater-Reliability/blob/master/IrrKrippendorf.py}}.

\subsection{Step 1 - Getting setup}\label{step-1---getting-setup}

The first step is to save the ``IRR\_Automation.R'' script and your xslx
or csv files in the same folder on your computer and set this folder as
your working directory.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# dir<-"C:/Users/Desktop/Automation IRR"}
\CommentTok{# setwd(dir)}
\end{Highlighting}
\end{Shaded}

You then need to install the required packages to run the script

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# install.packages('irr')}
\CommentTok{# install.packages('data.table')}
\CommentTok{# install.packages('plyr')}
\CommentTok{# install.packages('dplyr')}
\CommentTok{# install.packages('reshape2')}
\CommentTok{# install.packages('splitstackshape')}
\CommentTok{# install.packages('tidyverse')}
\CommentTok{#install.packages('tinytex')}
\end{Highlighting}
\end{Shaded}

and load the installed packages.

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{library}\NormalTok{(irr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'irr' was built under R version 3.5.3
\end{verbatim}

\begin{verbatim}
## Loading required package: lpSolve
\end{verbatim}

\begin{verbatim}
## Warning: package 'lpSolve' was built under R version 3.5.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# library(data.table)}
 \KeywordTok{library}\NormalTok{(plyr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'plyr' was built under R version 3.5.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# library(dplyr)}
\CommentTok{# library(reshape2)}
\CommentTok{# library(splitstackshape)}
\CommentTok{# library(tidyverse)}
\CommentTok{#library(tinytex)}
\end{Highlighting}
\end{Shaded}

\subsection{Step 2 - Loading the data}\label{step-2---loading-the-data}

Once the working directory has been established and you have loaded the
required packages to run the script, the next step is to load the data.
We are using two csv files that contain binary data from two coders
which has been parsed from JSON files by the python script which can be
found here
\textbf{\url{https://github.com/HumanBehaviourChangeProject/Automation-InterRater-Reliability}}.
In this step we load the two separate files and as they had the same
format and headings we could combine them as a `data.frame' using
`rbind'. We used `na.omit' to ensure that there is no missing data with
listwise deletion of missing values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{File1<-}\KeywordTok{read.csv}\NormalTok{(}\StringTok{"Behaviour1.csv"}\NormalTok{, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{,}\DataTypeTok{sep =} \StringTok{","}\NormalTok{)}
\NormalTok{File2<-}\KeywordTok{read.csv}\NormalTok{(}\StringTok{"Behaviour2.csv"}\NormalTok{, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{,}\DataTypeTok{sep =} \StringTok{","}\NormalTok{)}
\NormalTok{DataFile<-}\KeywordTok{rbind.data.frame}\NormalTok{(File1, File2)}
\NormalTok{DataFile<-}\KeywordTok{na.omit}\NormalTok{(DataFile)}
\KeywordTok{head}\NormalTok{(DataFile, }\DataTypeTok{n=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    paperID     shortTitle AttributeId                     AttributeTitle
## 1 34829909 Aveyard (2001)     4788957              Geographical location
## 2 34829909 Aveyard (2001)     4788958            Country of intervention
## 3 34829909 Aveyard (2001)     4788959    Lower-level geographical region
## 4 34829909 Aveyard (2001)     5295657              Attribute of location
## 5 34829909 Aveyard (2001)     4788960 Area social and economic condition
##      ArmTitle Coder1Text Coder2Text
## 1 Whole Study          0          0
## 2 Whole Study          1          1
## 3 Whole Study          1          1
## 4 Whole Study          0          0
## 5 Whole Study          0          0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(DataFile)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "paperID"        "shortTitle"     "AttributeId"    "AttributeTitle"
## [5] "ArmTitle"       "Coder1Text"     "Coder2Text"
\end{verbatim}

\subsection{Step 3 - Restructuring the
data}\label{step-3---restructuring-the-data}

The DataFile data.frame has more columns of data than we need to
calculate \emph{krippendorf's alpha}. We want to calculate the agreement
between Coder1 (Coder1Text) and Coder2 (Coder2Text) for each attribute
(AttributeID/AttributeTitle) in all papers (shortTitle) that were
annotated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DataFile_Attributes<-DataFile[,}\KeywordTok{c}\NormalTok{((}\DecValTok{4}\NormalTok{),(}\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{),(}\DecValTok{6}\OperatorTok{:}\DecValTok{7}\NormalTok{))]}
\KeywordTok{head}\NormalTok{(DataFile_Attributes, }\DataTypeTok{n=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                       AttributeTitle     shortTitle AttributeId Coder1Text
## 1              Geographical location Aveyard (2001)     4788957          0
## 2            Country of intervention Aveyard (2001)     4788958          1
## 3    Lower-level geographical region Aveyard (2001)     4788959          1
## 4              Attribute of location Aveyard (2001)     5295657          0
## 5 Area social and economic condition Aveyard (2001)     4788960          0
##   Coder2Text
## 1          0
## 2          1
## 3          1
## 4          0
## 5          0
\end{verbatim}

We want to check how many papers were annotated and how many attributes
we want to calculate the statistic for.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{NumPapers<-}\KeywordTok{unique}\NormalTok{(DataFile_Attributes}\OperatorTok{$}\NormalTok{shortTitle)}
\NormalTok{NumEntities<-}\KeywordTok{unique}\NormalTok{(DataFile_Attributes}\OperatorTok{$}\NormalTok{AttributeTitle)}
\KeywordTok{length}\NormalTok{(NumPapers)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(NumEntities)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 70
\end{verbatim}

This tells us that we have annotated data for 50 papers and for 70
unique attributes.

\subsection{Step 4 - Finding attributes with
data}\label{step-4---finding-attributes-with-data}

We want to calcualate IRR for the entire dataset and for each attribute
but as there are many entities we want to check if any of them have not
been annotated at all for the 50 papers to exclude them from the final
analysis. To check this we simply count the annotations for each
attribute.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AttributeCount<-}\KeywordTok{ddply}\NormalTok{(DataFile_Attributes, }\StringTok{"AttributeTitle"}\NormalTok{, }\KeywordTok{numcolwise}\NormalTok{(sum))}
\KeywordTok{tail}\NormalTok{(AttributeCount)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         AttributeTitle AttributeId Coder1Text Coder2Text
## 65 Temporary residence   241468730          0          0
## 66      Transportation   241471940          0          0
## 67 University facility   241471100          0          2
## 68          Urban area   241468250          4          4
## 69 Vocational facility   246361044          2          2
## 70               Water   247280720          0          0
\end{verbatim}

This allows us to find the attributes that have data for at least one
coder and those that have no data at all for either coder 1 or coder 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{HasData<-}\KeywordTok{as.data.frame}\NormalTok{(AttributeCount[ }\KeywordTok{which}\NormalTok{(AttributeCount}\OperatorTok{$}\NormalTok{Coder1Text }\OperatorTok{>}\StringTok{ }\DecValTok{0} \OperatorTok{|}\StringTok{ }\NormalTok{AttributeCount}\OperatorTok{$}\NormalTok{Coder2Text }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{), ])}
\NormalTok{HasNoData<-}\KeywordTok{as.data.frame}\NormalTok{(AttributeCount[ }\KeywordTok{which}\NormalTok{(AttributeCount}\OperatorTok{$}\NormalTok{Coder1Text }\OperatorTok{==}\StringTok{ }\DecValTok{0} \OperatorTok{&}\StringTok{ }\NormalTok{AttributeCount}\OperatorTok{$}\NormalTok{Coder2Text }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{), ])}
\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(HasData}\OperatorTok{$}\NormalTok{AttributeTitle))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(HasData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                         AttributeTitle AttributeId Coder1Text Coder2Text
## 8        Community healthcare facility   264782910          1          3
## 10             Country of intervention   241468000         20         15
## 13    Doctor-led primary care facility   241469270          9          7
## 17       Emergency department facility   241470750          1          1
## 18                            Facility   241468350          3          1
## 23                 Healthcare facility   241468780          3          4
## 27                   Hospital facility   241468830          1          1
## 28 Hospital outpatient clinic facility   241470620          4          4
## 30                 Household residence   241468480          2          1
## 33     Lower-level geographical region   241468050         33         26
## 38                     Office facility   241471630          0          1
## 39                 Outdoor environment   246362154          1          1
## 46                      Primary school   241470950          1          1
## 48                Psychiatric facility   241610380          1          1
## 52                   Research facility   246260630          3          2
## 54                Residential facility   241468430          1          1
## 57                          Rural area   241468200          2          1
## 58                     School facility   241470900          2          1
## 59                    Secondary school   241471000          5          5
## 62         Sport and exercise facility   246361248          1          1
## 64                       Suburban area   264782840          3          3
## 67                 University facility   241471100          0          2
## 68                          Urban area   241468250          4          4
## 69                 Vocational facility   246361044          2          2
\end{verbatim}

Now that we know there are only 24 attributes with data we can subset
the original data.frame so that it includes attributes with data only
and order the data.frame by the headers of AttributeTitle and
shortTitle.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{NewData<-}\KeywordTok{match_df}\NormalTok{(DataFile_Attributes, HasData, }\DataTypeTok{on =} \StringTok{"AttributeTitle"}\NormalTok{)}
\NormalTok{NewData<-NewData[}\KeywordTok{order}\NormalTok{(NewData}\OperatorTok{$}\NormalTok{AttributeTitle, NewData}\OperatorTok{$}\NormalTok{shortTitle),]}
\end{Highlighting}
\end{Shaded}

\subsection{Step 5 - Calculating IRR using
kripp.alpha}\label{step-5---calculating-irr-using-kripp.alpha}

We can now calculate \emph{krippendorf's alpha} for the entire
data.frame with and without data. The `kripp.alpha' function requires
the data to be in a table format and calculates IRR for all columns. We
further subset the data to just include the columns with data for Coder1
and Coder2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{All_Attributes<-}\KeywordTok{t}\NormalTok{(DataFile_Attributes[,}\DecValTok{4}\OperatorTok{:}\DecValTok{5}\NormalTok{])}
\NormalTok{Result<-}\KeywordTok{kripp.alpha}\NormalTok{(All_Attributes, }\DataTypeTok{method =} \KeywordTok{c}\NormalTok{(}\StringTok{"ordinal"}\NormalTok{))}
\NormalTok{Statistic<-}\KeywordTok{as.character}\NormalTok{(}\StringTok{"All Entities"}\NormalTok{)}
\NormalTok{Value<-}\KeywordTok{as.numeric}\NormalTok{(Result}\OperatorTok{$}\NormalTok{value)}
\NormalTok{All_Data_Result<-}\KeywordTok{data.frame}\NormalTok{(Statistic,Value)}
\KeywordTok{print}\NormalTok{(All_Data_Result)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Statistic     Value
## 1 All Entities 0.7322859
\end{verbatim}

We are more interested in the alpha value for the attributes with data
only as we are assuming that the value for the entire dataset will be
inflated by the attributes with no data for either coder as they would
technically have perfect agreeement. For this reason we do a second
calcuation on the subset of data with attributes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Attributes_with_Data<-}\KeywordTok{t}\NormalTok{(NewData[,}\DecValTok{4}\OperatorTok{:}\DecValTok{5}\NormalTok{])}
\NormalTok{Attributes_with_Data<-}\KeywordTok{na.omit}\NormalTok{(Attributes_with_Data)}
\NormalTok{Result<-}\KeywordTok{kripp.alpha}\NormalTok{(Attributes_with_Data, }\DataTypeTok{method =} \KeywordTok{c}\NormalTok{(}\StringTok{"ordinal"}\NormalTok{))}
\NormalTok{Statistic<-}\KeywordTok{as.character}\NormalTok{(}\StringTok{"Entities with data"}\NormalTok{)}
\NormalTok{Value<-}\KeywordTok{as.numeric}\NormalTok{(Result}\OperatorTok{$}\NormalTok{value)}
\NormalTok{Attribute_Result<-}\KeywordTok{data.frame}\NormalTok{(Statistic,Value)}
\KeywordTok{print}\NormalTok{(Attribute_Result)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            Statistic     Value
## 1 Entities with data 0.7171377
\end{verbatim}

Our final calculation is for each of the attributes indiviually, with or
without data, which requires us to loop over each of the attributes in
turn. we want to print all the results in a new data.frame
`all\_results'.

Our for loop creates a data.frame with the values for Coder1 and Coder2
only for each attribute in turn and calculates kripp.alpha for each
attribute. As we loop over each attribute we need to save the alpha
values storing the values in a temporary `new\_data\_frame' before
moving onto the next attribute.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all_results<-}\KeywordTok{data.frame}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (attributetitle }\ControlFlowTok{in} \KeywordTok{unique}\NormalTok{(NewData}\OperatorTok{$}\NormalTok{AttributeTitle)) \{}
  
\NormalTok{  temp_data =}\StringTok{ }\NormalTok{NewData[NewData}\OperatorTok{$}\NormalTok{AttributeTitle}\OperatorTok{==}\NormalTok{attributetitle,]}
\NormalTok{  temp_data}\OperatorTok{$}\NormalTok{Coder1Text<-}\KeywordTok{as.numeric}\NormalTok{(temp_data}\OperatorTok{$}\NormalTok{Coder1Text)}
\NormalTok{  temp_data}\OperatorTok{$}\NormalTok{Coder2Text<-}\KeywordTok{as.numeric}\NormalTok{(temp_data}\OperatorTok{$}\NormalTok{Coder2Text)}
  
\NormalTok{  temp_data2<-}\KeywordTok{t}\NormalTok{(temp_data[}\DecValTok{4}\OperatorTok{:}\DecValTok{5}\NormalTok{])}
  
\NormalTok{  result<-}\KeywordTok{kripp.alpha}\NormalTok{(temp_data2, }\DataTypeTok{method =} \KeywordTok{c}\NormalTok{(}\StringTok{"ordinal"}\NormalTok{))}
\NormalTok{  value<-}\KeywordTok{as.numeric}\NormalTok{(result}\OperatorTok{$}\NormalTok{value)}
  
\NormalTok{  new_data_frame =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{AttributeTitle=}\NormalTok{attributetitle,}\DataTypeTok{Result=}\NormalTok{value)}
  
\NormalTok{  all_results <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(all_results,new_data_frame)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We then join all the values together in our `all\_results' data.frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all_results <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(all_results,new_data_frame)}
\end{Highlighting}
\end{Shaded}

We want to create an output which will have all the alpha scores which
we calculated, for the whole dataset, the attributes with data subset
and the individual entities and so we first join the two alphas score
and rename the column headers to match with the `all\_results'
data.frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{WholeSample<-}\KeywordTok{rbind}\NormalTok{(All_Data_Result,Attribute_Result)}
\KeywordTok{names}\NormalTok{(WholeSample) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"AttributeTitle"}\NormalTok{, }\StringTok{"Result"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We then add both data.frames together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AllResults <-}\KeywordTok{rbind}\NormalTok{(all_results, WholeSample)}
\KeywordTok{head}\NormalTok{(AllResults, }\DataTypeTok{n=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                         AttributeTitle      Result
## 1        Community healthcare facility  0.48437500
## 2              Country of intervention  0.78241758
## 3     Doctor-led primary care facility  0.70535714
## 4        Emergency department facility  1.00000000
## 5                             Facility  0.48437500
## 6                  Healthcare facility  0.23963134
## 7                    Hospital facility  1.00000000
## 8  Hospital outpatient clinic facility  0.73097826
## 9                  Household residence -0.02061856
## 10     Lower-level geographical region  0.71351798
\end{verbatim}

Finally we write the output to a csv.file.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{write.csv}\NormalTok{(AllResults, }\StringTok{"IRR_Results_AlphaValues.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}


\end{document}
